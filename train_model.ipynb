{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa6c55f8-ffcd-4433-b3be-1163828f75f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (3.8.5)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from spacy) (0.15.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from spacy) (4.66.5)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from spacy) (2.2.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from spacy) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from spacy) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\bhuva\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.0)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import (auto-generated because you didn't call 'numpy.import_array()' after cimporting numpy; use '<void>numpy._import_array' to disable if you are certain you don't need it).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, Iterable, Union\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# set library-specific custom warning handling before doing anything else\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setup_default_warnings\n\u001b[0;32m      8\u001b[0m setup_default_warnings()  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# These are imported as part of the API\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\errors.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Literal\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mErrorsWithCodes\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, code):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\spacy\\compat.py:39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatalogue\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _importlib_metadata \u001b[38;5;28;01mas\u001b[39;00m importlib_metadata  \u001b[38;5;66;03m# type: ignore[no-redef]    # noqa: F401\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthinc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optimizer  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     41\u001b[0m pickle \u001b[38;5;241m=\u001b[39m pickle\n\u001b[0;32m     42\u001b[0m copy_reg \u001b[38;5;241m=\u001b[39m copy_reg\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\api.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      2\u001b[0m     CupyOps,\n\u001b[0;32m      3\u001b[0m     MPSOps,\n\u001b[0;32m      4\u001b[0m     NumpyOps,\n\u001b[0;32m      5\u001b[0m     Ops,\n\u001b[0;32m      6\u001b[0m     get_current_ops,\n\u001b[0;32m      7\u001b[0m     get_ops,\n\u001b[0;32m      8\u001b[0m     set_current_ops,\n\u001b[0;32m      9\u001b[0m     set_gpu_allocator,\n\u001b[0;32m     10\u001b[0m     use_ops,\n\u001b[0;32m     11\u001b[0m     use_pytorch_for_gpu_memory,\n\u001b[0;32m     12\u001b[0m     use_tensorflow_for_gpu_memory,\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m enable_mxnet, enable_tensorflow, has_cupy\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config, ConfigValidationError, registry\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\backends\\__init__.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cupy_allocators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cupy_pytorch_allocator, cupy_tensorflow_allocator\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_server\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParamServer\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcupy_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CupyOps\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmps_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MPSOps\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NumpyOps\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\backends\\cupy_ops.py:16\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     is_cupy_array,\n\u001b[0;32m      8\u001b[0m     is_mxnet_gpu_array,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m     torch2xp,\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _custom_kernels\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NumpyOps\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Ops\n\u001b[0;32m     20\u001b[0m \u001b[38;5;129m@registry\u001b[39m\u001b[38;5;241m.\u001b[39mops(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCupyOps\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCupyOps\u001b[39;00m(Ops):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\thinc\\backends\\numpy_ops.pyx:1\u001b[0m, in \u001b[0;36minit thinc.backends.numpy_ops\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: numpy.core.multiarray failed to import (auto-generated because you didn't call 'numpy.import_array()' after cimporting numpy; use '<void>numpy._import_array' to disable if you are certain you don't need it)."
     ]
    }
   ],
   "source": [
    "%pip install spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Text Preprocessing & NLP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5760b2b-7a64-4613-98fd-661b16a5cd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (11200, 5)\n",
      "Testing Data Shape: (2800, 5)\n",
      "===== Naive Bayes =====\n",
      "Accuracy: 0.9817857142857143\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     business       0.98      0.97      0.97       407\n",
      "    education       1.00      0.97      0.99       398\n",
      "entertainment       0.98      0.99      0.99       402\n",
      "       health       0.99      1.00      0.99       386\n",
      "     politics       1.00      0.99      0.99       393\n",
      "       sports       0.99      0.99      0.99       396\n",
      "   technology       0.95      0.97      0.96       418\n",
      "\n",
      "     accuracy                           0.98      2800\n",
      "    macro avg       0.98      0.98      0.98      2800\n",
      " weighted avg       0.98      0.98      0.98      2800\n",
      "\n",
      "\n",
      "\n",
      "===== Logistic Regression =====\n",
      "Accuracy: 0.9875\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     business       0.98      0.99      0.98       407\n",
      "    education       0.99      0.98      0.99       398\n",
      "entertainment       0.99      0.99      0.99       402\n",
      "       health       1.00      1.00      1.00       386\n",
      "     politics       1.00      1.00      1.00       393\n",
      "       sports       0.98      0.99      0.99       396\n",
      "   technology       0.96      0.97      0.97       418\n",
      "\n",
      "     accuracy                           0.99      2800\n",
      "    macro avg       0.99      0.99      0.99      2800\n",
      " weighted avg       0.99      0.99      0.99      2800\n",
      "\n",
      "\n",
      "\n",
      "===== Support Vector Machine =====\n",
      "Accuracy: 0.9889285714285714\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     business       0.98      0.98      0.98       407\n",
      "    education       0.99      0.99      0.99       398\n",
      "entertainment       1.00      0.99      0.99       402\n",
      "       health       1.00      1.00      1.00       386\n",
      "     politics       1.00      1.00      1.00       393\n",
      "       sports       0.99      0.99      0.99       396\n",
      "   technology       0.97      0.97      0.97       418\n",
      "\n",
      "     accuracy                           0.99      2800\n",
      "    macro avg       0.99      0.99      0.99      2800\n",
      " weighted avg       0.99      0.99      0.99      2800\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Load Dataset\n",
    "df = pd.read_csv('final_combined_news_data.csv')\n",
    "\n",
    "# Split Dataset\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training Data Shape:\", train.shape)\n",
    "print(\"Testing Data Shape:\", test.shape)\n",
    "\n",
    "# TF-IDF Vectorizer for each feature\n",
    "tfidf_headline = TfidfVectorizer(max_features=1500)\n",
    "tfidf_desc = TfidfVectorizer(max_features=1500)\n",
    "tfidf_content = TfidfVectorizer(max_features=2000)\n",
    "\n",
    "# Fit Transform on Train Data\n",
    "X_train_headline = tfidf_headline.fit_transform(train['headlines'])\n",
    "X_train_desc = tfidf_desc.fit_transform(train['description'])\n",
    "X_train_content = tfidf_content.fit_transform(train['content'])\n",
    "\n",
    "# Transform on Test Data\n",
    "X_test_headline = tfidf_headline.transform(test['headlines'])\n",
    "X_test_desc = tfidf_desc.transform(test['description'])\n",
    "X_test_content = tfidf_content.transform(test['content'])\n",
    "\n",
    "# Combine all TF-IDF features\n",
    "X_train_combined = hstack([X_train_headline, X_train_desc, X_train_content])\n",
    "X_test_combined = hstack([X_test_headline, X_test_desc, X_test_content])\n",
    "\n",
    "# Target Values\n",
    "y_train = train['category']\n",
    "y_test = test['category']\n",
    "\n",
    "# Machine Learning Models\n",
    "models = {\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Support Vector Machine\": LinearSVC()\n",
    "}\n",
    "\n",
    "# Train and Evaluate Models\n",
    "for name, model in models.items():\n",
    "    print(f\"===== {name} =====\")\n",
    "    model.fit(X_train_combined, y_train)\n",
    "    y_pred = model.predict(X_test_combined)\n",
    "    \n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a326646d-174e-47ed-b93a-dd3222296ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_content.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save Naive Bayes Model\n",
    "joblib.dump(model, 'naive_bayes_model.pkl')\n",
    "\n",
    "# Save Logistic Regression Model\n",
    "joblib.dump(model, 'logistic_regression_model.pkl')\n",
    "\n",
    "# Save Support Vector Machine Model\n",
    "joblib.dump(model, 'svm_model.pkl')\n",
    "\n",
    "# Save TF-IDF Vectorizers\n",
    "joblib.dump(tfidf_headline, 'tfidf_headline.pkl')\n",
    "joblib.dump(tfidf_desc, 'tfidf_description.pkl')\n",
    "joblib.dump(tfidf_content, 'tfidf_content.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3603078d-f96c-4c78-9979-1b78587c0c5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'news_classifier_model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load Model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m loaded_model \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnews_classifier_model.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m loaded_model1 \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogistic_regression_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m loaded_model2 \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvm_model.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    648\u001b[0m         obj \u001b[38;5;241m=\u001b[39m _unpickle(fobj)\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    651\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m fobj:\n\u001b[0;32m    652\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'news_classifier_model.pkl'"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "loaded_model = joblib.load('news_classifier_model.pkl')\n",
    "loaded_model1 = joblib.load('logistic_regression_model.pkl')\n",
    "loaded_model2 = joblib.load('svm_model.pkl')\n",
    "\n",
    "\n",
    "# Load Vectorizers\n",
    "loaded_headline = joblib.load('tfidf_headline.pkl')\n",
    "loaded_desc = joblib.load('tfidf_desc.pkl')\n",
    "loaded_content = joblib.load('tfidf_content.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
